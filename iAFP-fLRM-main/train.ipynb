{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8082e5-12eb-4c0e-860b-e85cd22e467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from termcolor import colored\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve, average_precision_score\n",
    "from model import Net\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(data_iter, net, epoch):\n",
    "    pred_prob = []\n",
    "    label_pred = []\n",
    "    label_real = []\n",
    "    rep_list = []\n",
    "    true_labels = []\n",
    "    for x, pos, hf, y in data_iter:\n",
    "        outputs, rep = net(x, pos, hf)\n",
    "        pred_prob_positive = outputs[:, 1]\n",
    "        pred_prob = pred_prob + pred_prob_positive.tolist()\n",
    "        label_pred = label_pred + outputs.argmax(dim=1).tolist()\n",
    "        label_real = label_real + y.tolist()\n",
    "        label = y.cpu()\n",
    "        if rep is not None and rep.numel() > 0:\n",
    "            rep = rep.cpu()\n",
    "            rep_list.append(rep.detach().numpy())\n",
    "        else:\n",
    "            rep_list.append(None)\n",
    "        true_labels.append(label.detach().numpy())\n",
    "    performance, roc_data, prc_data = caculate_metric(pred_prob, label_pred, label_real, epoch)\n",
    "    return performance, roc_data, prc_data, rep_list, label_real, true_labels\n",
    "\n",
    "\n",
    "def caculate_metric(pred_prob, label_pred, label_real, epoch):\n",
    "    test_num = len(label_real)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if label_real[index] == 1:\n",
    "            if label_real[index] == label_pred[index]:\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if label_real[index] == label_pred[index]:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "    ACC = float(tp + tn) / test_num\n",
    "    Sensitivity = float(tp) / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    Specificity = float(tn) / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))) if (tp + fp) * (\n",
    "                tp + fn) * (tn + fp) * (tn + fn) != 0 else 0\n",
    "    FPR, TPR, thresholds = roc_curve(label_real, pred_prob, pos_label=1)\n",
    "    AUC = auc(FPR, TPR)\n",
    "    precision, recall, thresholds = precision_recall_curve(label_real, pred_prob, pos_label=1)\n",
    "    AP = average_precision_score(label_real, pred_prob, average='macro', pos_label=1, sample_weight=None)\n",
    "    performance = [ACC, Sensitivity, Specificity, AUC, MCC]\n",
    "    roc_data = [FPR, TPR, AUC]\n",
    "    prc_data = [recall, precision, AP]\n",
    "    return performance, roc_data, prc_data\n",
    "\n",
    "\n",
    "def reg_loss(net, output, label):\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "    l2_lambda = 0.0\n",
    "    regularization_loss = 0\n",
    "    for param in net.parameters():\n",
    "        regularization_loss += torch.norm(param, p=2)\n",
    "    total_regularization_loss = l2_lambda * regularization_loss\n",
    "    total_loss = criterion(output.to(device), label.to(device)) + total_regularization_loss.to(device)\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def train_test(train_iter, test_iter):\n",
    "    net = Net()\n",
    "    net = net.to(device)\n",
    "    lr = 0.002\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    best_acc = 0\n",
    "    best_ind_acc = 0\n",
    "    EPOCH = 200\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls = []\n",
    "        t0 = time.time()\n",
    "        net.train()\n",
    "        for seq, pos, hf, label in train_iter:\n",
    "            output, _ = net(seq, pos, hf)\n",
    "            loss = reg_loss(net, output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_ls.append(loss.item())\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            train_performance, train_roc_data, train_prc_data, train_rep_list, train_label_real, train_true_labels = evaluate(\n",
    "                train_iter, net, epoch)\n",
    "            test_performance, test_roc_data, test_prc_data, test_rep_list, test_label_real, test_true_labels = evaluate(\n",
    "                test_iter, net, epoch)\n",
    "        results = f\"\\nepoch: {epoch + 1}, loss: {np.mean(loss_ls):.5f}\\n\"\n",
    "        results += f'train_acc: {train_performance[0]:.4f}, time: {time.time() - t0:.2f}'\n",
    "        results += '\\n' + '=' * 16 + ' Test Performance. Epoch[{}] '.format(epoch + 1) + '=' * 16 \\\n",
    "                   + '\\n[ACC,\\tSP,\\t\\tSE,\\t\\tAUC,\\tMCC]\\n' + '{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f}'.format(\n",
    "            test_performance[0], test_performance[2], test_performance[1], test_performance[3],\n",
    "            test_performance[4])\n",
    "        print(results)\n",
    "        test_acc = test_performance[0]\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_performance = test_performance\n",
    "            filename = '{}, {}[{:.4f}].pt'.format('H_A_Model' + ', epoch[{}]'.format(epoch + 1), 'ACC', best_acc)\n",
    "            save_path_pt = os.path.join('file', filename)\n",
    "            best_results = '\\n' + '=' * 16 + colored(' Best Performance. Epoch[{}] ', 'red').format(\n",
    "                epoch + 1) + '=' * 16 \\\n",
    "                           + '\\n[ACC,\\tSP,\\t\\tSE,\\t\\tAUC,\\tMCC]\\n' + '{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f}'.format(\n",
    "                best_performance[0], best_performance[2], best_performance[1], best_performance[3],\n",
    "                best_performance[4]) + '\\n' + '=' * 60\n",
    "            best_ROC = test_roc_data\n",
    "            best_PRC = test_prc_data\n",
    "\n",
    "    return best_performance, best_results, best_ROC, best_PRC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efddc2e-dac2-434d-b20a-f3fe4b977da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "================ Test Performance. Epoch[100] ================\n",
    "[ACC,\tSP,\t\tSE,\t\tAUC,\tMCC]\n",
    "0.9038,\t0.8729,\t0.9347,\t0.9615,\t0.8091"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
